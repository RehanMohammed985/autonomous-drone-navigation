# Autonomous Drone Navigation System

An AI-powered drone navigation framework built for real-time obstacle avoidance and path planning using deep reinforcement learning, computer vision, and SLAM-based state estimation. Designed for use in both simulation (AirSim) and deployment on small drones powered by Jetson Nano or Raspberry Pi + Realsense.

## ğŸ§  System Overview

- **Perception**: YOLOv8 + depth estimation for obstacle detection.
- **Localization**: ORB-SLAM2 or RTAB-Map for visual-inertial odometry.
- **Control**: DRL policy trained with PPO via Stable Baselines3.
- **Fallback Planner**: Grid-based A* for fail-safe navigation.
- **Simulator**: AirSim API for flight data and training episodes.

## ğŸ§° Tech Stack

- Python, PyTorch, OpenCV, ROS2, Stable Baselines3, AirSim
- Optional deployment on PX4 autopilot via MAVROS

## ğŸ“ Structure

autonomous-drone-navigation/
â”œâ”€â”€ train_policy.py # PPO training pipeline
â”œâ”€â”€ test_policy.py # Evaluation/testing loop
â”œâ”€â”€ configs/ # Drone specs and training params
â”œâ”€â”€ perception/ # Obstacle and depth processing
â”œâ”€â”€ control/ # DRL policy + planner logic
â”œâ”€â”€ sim/ # AirSim API wrappers
â”œâ”€â”€ utils/ # Logging, metrics
â”œâ”€â”€ launch/ # Launch configs (AirSim, PX4)
â””â”€â”€ README.md

## ğŸš€ Usage

### Install Dependencies

~bash~
pip install -r requirements.txt
Launch AirSim Simulation
ros2 launch launch/airsim.launch
Train Policy
python train_policy.py --config configs/drone_config.yaml
Test Policy
python test_policy.py --model checkpoints/ppo_drone_policy.zip
ğŸ” Training Details

Reward: +1 goal, -10 collision, -1 per timestep
Curriculum: Easy â†’ Dense environments
Simulation using AirSim gym environment
DRL algorithm: PPO (Stable Baselines3)
ğŸ“Š Performance

94.5% success rate in dense AirSim scenarios
Real-time obstacle avoidance at 18ms control loop latency on Jetson Nano
ğŸ“ License
    MIT
